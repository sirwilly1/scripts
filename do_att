import time
import math
from pathlib import Path

from rich.console import Console, Group
from rich.live import Live
from rich.panel import Panel

# ----------------- CONFIG -----------------
LOG_FILE = "dos_stealthy_flood.log"

# Max number of points we keep in memory (smooth scrolling window)
MAX_POINTS_ON_CHART = 120

# How often we poll the log file (seconds)
REFRESH_INTERVAL = 1.0

# Threshold for "high" failure rate (color red above this)
HIGH_FAILURE_THRESHOLD = 10

# Moving average window (seconds) for failures/sec
MOVING_AVG_WINDOW = 10

# Spike detection (for failures/sec)
SPIKE_FACTOR = 2.0
SPIKE_MIN_BASELINE = 3
# ------------------------------------------


console = Console()


def read_counts_since(log_path: Path, last_pos: int):
    """
    Read new lines from the log and return:
    - failures_this_second
    - requests_this_second
    - new file position

    Every non-empty line is treated as a request.
    Any line containing '[FAILURE]' is a failure.
    """
    failures = 0
    requests = 0

    with log_path.open("r", encoding="utf-8", errors="ignore") as f:
        f.seek(last_pos)
        lines = f.readlines()
        new_pos = f.tell()

    for line in lines:
        if line.strip():
            requests += 1
        if "[FAILURE]" in line:
            failures += 1

    return failures, requests, new_pos


def moving_average(data, window):
    if not data:
        return 0.0
    w = min(window, len(data))
    return sum(data[-w:]) / w


def render_failures_panel(all_data, max_columns):
    """Top panel: failures per second with colors, MA, spikes, etc."""
    if not all_data:
        return Panel("Waiting for failure data...", title="Failures per Second (Realtime)")

    # Smooth scrolling / crop to width
    data = all_data[-max_columns:]

    window_seconds = len(data)
    real_max_val = max(data)
    real_min_val = min(data)
    last_val = data[-1]
    prev_val = data[-2] if len(data) >= 2 else None
    avg_val = moving_average(data, MOVING_AVG_WINDOW)

    # If everything in the visible window is zero, draw a flat line and bail early
    if real_max_val == 0 and real_min_val == 0:
        label = "  0 │" + " " * len(data)
        axis = "    └" + ("─" * len(data))
        info_line = f"Last {window_seconds} seconds | all failure counts are 0"
        chart_text = label + "\n" + axis + "\n\n" + info_line
        return Panel(chart_text, title="Failures per Second (Realtime)")

    # For indexing, use simple loops (cannot fail)
    max_idx = max(range(len(data)), key=lambda i: data[i])
    min_idx = min(range(len(data)), key=lambda i: data[i])

    # For Y-axis scaling, ensure we don't divide by 0
    scaled_max_val = max(real_max_val, 1)

    # Y-axis levels
    max_height = 12
    step = max(1, math.ceil(scaled_max_val / max_height))
    levels = list(range(0, scaled_max_val + 1, step))
    if levels[-1] != scaled_max_val:
        levels[-1] = scaled_max_val
    levels = sorted(set(levels), reverse=True)

    # Level closest to moving average
    avg_level = min(levels, key=lambda lv: abs(lv - avg_val))

    lines = []

    for level in levels:
        label = f"{level:>3} │"
        row_chars = []

        for i, v in enumerate(data):
            char = " "

            # Bars (colored)
            if v >= level and level != 0:
                if v >= HIGH_FAILURE_THRESHOLD:
                    color = "red"
                else:
                    color = "green"

                # Highlight max/min
                if i == max_idx:
                    color = "yellow"
                elif i == min_idx:
                    color = "cyan"

                char = f"[{color}]█[/]"

            # Moving average line
            if level == avg_level and v < level:
                char = "[bright_blue]·[/]"

            row_chars.append(char)

        lines.append(label + "".join(row_chars))

    # X axis (no tick labels)
    axis = "    └" + ("─" * len(data))

    max_info = f"max={real_max_val} at t=-{window_seconds - 1 - max_idx}s"
    min_info = f"min={real_min_val} at t=-{window_seconds - 1 - min_idx}s"
    avg_info = f"{MOVING_AVG_WINDOW}s MA={avg_val:.2f}"
    last_n_label = f"Last {window_seconds} seconds"

    spike_msg = ""
    if prev_val is not None:
        if last_val >= SPIKE_MIN_BASELINE and last_val >= prev_val * SPIKE_FACTOR:
            spike_msg = f"[bold red]SPIKE! last={last_val} prev={prev_val}[/]"

    info_line = f"{last_n_label} | {max_info} | {min_info} | {avg_info}"
    if spike_msg:
        info_line += " | " + spike_msg

    chart_text = "\n".join(lines) + "\n" + axis + "\n\n" + info_line

    return Panel(chart_text, title="Failures per Second (Realtime)")


def render_total_requests_panel(all_cumulative, max_columns):
    """Bottom panel: total requests over time (cumulative)."""
    if not all_cumulative:
        return Panel("Waiting for request data...", title="Total Requests Over Time")

    cumulative_data = all_cumulative[-max_columns:]

    window_seconds = len(cumulative_data)
    real_max_val = max(cumulative_data)
    real_min_val = min(cumulative_data)

    # If cumulative is still all zero (no requests at all yet)
    if real_max_val == 0 and real_min_val == 0:
        label = "  0 │" + " " * len(cumulative_data)
        axis = "    └" + ("─" * len(cumulative_data))
        info_line = (
            f"Cumulative requests (last {window_seconds} seconds visible) | "
            f"min={real_min_val}, max={real_max_val}"
        )
        chart_text = label + "\n" + axis + "\n\n" + info_line
        return Panel(chart_text, title="Total Requests Over Time")

    scaled_max_val = max(real_max_val, 1)

    max_height = 12
    step = max(1, math.ceil(scaled_max_val / max_height))
    levels = list(range(0, scaled_max_val + 1, step))
    if levels[-1] != scaled_max_val:
        levels[-1] = scaled_max_val
    levels = sorted(set(levels), reverse=True)

    lines = []

    for level in levels:
        label = f"{level:>3} │"
        row_chars = []
        for v in cumulative_data:
            if v >= level and level != 0:
                char = "[blue]█[/]"
            else:
                char = " "
            row_chars.append(char)
        lines.append(label + "".join(row_chars))

    axis = "    └" + ("─" * len(cumulative_data))

    info_line = (
        f"Cumulative requests (last {window_seconds} seconds visible) | "
        f"min={real_min_val}, max={real_max_val}"
    )

    chart_text = "\n".join(lines) + "\n" + axis + "\n\n" + info_line

    return Panel(chart_text, title="Total Requests Over Time")


def render_dashboard(failure_counts, cumulative_requests, log_exists: bool):
    """Combine both panels into one renderable."""
    if not log_exists:
        return Panel(
            f"Waiting for log file '{LOG_FILE}'...",
            title="DoS Monitor",
        )

    # Shared autoresize width
    term_width = console.size.width
    label_width = 4
    sep_width = 2
    padding = 6
    max_columns = max(5, term_width - label_width - sep_width - padding)

    failures_panel = render_failures_panel(failure_counts, max_columns)
    requests_panel = render_total_requests_panel(cumulative_requests, max_columns)

    return Group(failures_panel, requests_panel)


def main():
    log_path = Path(LOG_FILE)
    failure_counts: list[int] = []
    request_counts: list[int] = []
    cumulative_requests: list[int] = []
    last_pos = 0

    # Start Live immediately, even if log file doesn't exist yet
    with Live(
        Panel(f"Waiting for log file '{LOG_FILE}'...", title="DoS Monitor"),
        console=console,
        refresh_per_second=4,
    ) as live:
        while True:
            log_exists = log_path.exists()

            if not log_exists:
                # No log file yet: clear data and show waiting message
                failure_counts.clear()
                request_counts.clear()
                cumulative_requests.clear()
                live.update(
                    render_dashboard(failure_counts, cumulative_requests, log_exists=False)
                )
                time.sleep(2)
                continue

            try:
                failures, requests, last_pos = read_counts_since(log_path, last_pos)
            except FileNotFoundError:
                # Race condition: file deleted between exists() and open()
                last_pos = 0
                failure_counts.clear()
                request_counts.clear()
                cumulative_requests.clear()
                live.update(
                    render_dashboard(failure_counts, cumulative_requests, log_exists=False)
                )
                time.sleep(2)
                continue

            # Per-second series
            failure_counts.append(failures)
            request_counts.append(requests)

            # Cumulative requests
            prev_total = cumulative_requests[-1] if cumulative_requests else 0
            cumulative_requests.append(prev_total + requests)

            # Smooth scrolling window for all series
            for lst in (failure_counts, request_counts, cumulative_requests):
                if len(lst) > MAX_POINTS_ON_CHART:
                    lst.pop(0)

            live.update(
                render_dashboard(failure_counts, cumulative_requests, log_exists=True)
            )
            time.sleep(REFRESH_INTERVAL)


if __name__ == "__main__":
    main()
